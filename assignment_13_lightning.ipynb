{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch\n",
    "from IPython.core.display import display\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.loggers import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://lightning.ai/docs/pytorch/stable/notebooks/lightning_examples/cifar10-baseline.html\n",
    "\n",
    "DATA_FOLDER = \"./data\"\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = int(os.cpu_count() / 2)\n",
    "print(NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import cifar10Utility, imageAugmentationUtility\n",
    "\n",
    "# import importlib\n",
    "# imageAugmentationUtility = importlib.reload(imageAugmentationUtility)\n",
    "\n",
    "train_transforms, test_transforms = imageAugmentationUtility.get_cifar10_train_and_test_transforms(cifar10Utility.get_mean(),\n",
    "                                                                                                   cifar10Utility.get_std())\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset  = cifar10Utility.get_datasets(train_transforms_collection=train_transforms,\n",
    "                                                                   test_transforms_collection=test_transforms,\n",
    "                                                                    data_folder=DATA_FOLDER)\n",
    "print(f\"Images in train_dataset are :{len(train_dataset)}, validation_dataset: {len(validation_dataset)}, and test_dataset: {len(test_dataset)}\")\n",
    "train_loader, validation_loader, test_loader = cifar10Utility.get_dataloaders(train_dataset=train_dataset,\n",
    "                                                                    validation_dataset=validation_dataset,\n",
    "                                                                    test_dataset=test_dataset,\n",
    "                                                                    num_workers=NUM_WORKERS,\n",
    "                                                                    batch_size=BATCH_SIZE)\n",
    "print(f\"Batches count in train data loader are :{len(train_loader)}, validation loader: {len(validation_loader)},and test data loader: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import commonUtility\n",
    "from utility import imageVisualizationUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "images, labels = commonUtility.get_random_images_from_data_loader(train_loader, images_count=8)\n",
    "labels = cifar10Utility.get_labels_names(labels_indexes=labels)\n",
    "print(labels)\n",
    "imageVisualizationUtility.show(images, labels)\n",
    "\n",
    "# show images using torch vision grid function\n",
    "# imageVisualizationUtility.show(torchvision.utils.make_grid(images), labels=\"-\".join(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print single image from test dataset\n",
    "import random\n",
    "image, label = test_dataset[random.randint(0,len(test_dataset)-1)]\n",
    "label = cifar10Utility.get_labels_names(labels_indexes=label)\n",
    "imageVisualizationUtility.show(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  models import modelHandler\n",
    "import torchmetrics\n",
    "import torchmetrics.classification\n",
    "# modelHandler = importlib.reload(modelHandler)\n",
    "\n",
    "model_handler = modelHandler.ModelHandler(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_handler.get_lightning_model_instance()\n",
    "model_handler.show_model_summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=30,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    logger=CSVLogger(save_dir=\"logs/\"), #[TensorBoardLogger(save_dir=\"logs/\"), CSVLogger(save_dir=\"logs/\")],\n",
    "    auto_lr_find=True,\n",
    "    callbacks=[LearningRateMonitor(logging_interval=\"step\"), TQDMProgressBar(refresh_rate=10)]\n",
    ")\n",
    "\n",
    "# Find the learning rate\n",
    "# result = trainer.tune(model, train_loader)\n",
    "lr_finder = trainer.tuner.lr_find(model, train_loader, validation_loader, num_training=200)\n",
    "new_lr = lr_finder.suggestion()\n",
    "print(f\"Suggested LR: {new_lr}\")\n",
    "fig = lr_finder.plot(suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting new learning rate\n",
    "model.hparams.lr = new_lr\n",
    "trainer.fit(model, train_loader, validation_loader)\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "\n",
    "del metrics[\"step\"]\n",
    "del metrics[\"valid_loss\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\"))\n",
    "sn.relplot(data=metrics, kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"lightning_resnet18.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model \n",
    "torch.save(model.state_dict(), f\"{trainer.logger.log_dir}/{MODEL_NAME}\")\n",
    "# Saving at top level as well\n",
    "torch.save(model.state_dict(), MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new model instance and loading weights\n",
    "# model_location = f\"{trainer.logger.log_dir}/lightning_resnet18.pth\"\n",
    "\n",
    "new_loaded_model = model_handler.get_lightning_model_instance(saved_model=MODEL_NAME)\n",
    "model_handler.show_model_summary(new_loaded_model)\n",
    "\n",
    "# Set the model to evaluation mode (disable dropout, randomness, etc.)\n",
    "new_loaded_model = new_loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_images, batch_labels = commonUtility.get_random_images_batch_and_labels_from_data_loader(test_loader)\n",
    "\n",
    "#  {\"images\" : images, \"predicted_labels\" : predicted_labels, \"actual_labels\" : actual_labels}\n",
    "non_matched_results, matched_results = commonUtility.get_images_for_matched_and_non_matched_model_predictions(new_loaded_model, batch_images, batch_labels, max_image_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Matched results\")\n",
    "predicted_labels_names = cifar10Utility.get_labels_names(labels_indexes=matched_results[\"predicted_labels\"])\n",
    "actual_labels_names = cifar10Utility.get_labels_names(labels_indexes=matched_results[\"actual_labels\"])\n",
    "matched_combined_labels = commonUtility.combine_labels(predicted_labels_names, actual_labels_names)\n",
    "imageVisualizationUtility.show(matched_results[\"images\"], matched_combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Non-Matched results\")\n",
    "predicted_labels_names = cifar10Utility.get_labels_names(labels_indexes=non_matched_results[\"predicted_labels\"])\n",
    "actual_labels_names = cifar10Utility.get_labels_names(labels_indexes=non_matched_results[\"actual_labels\"])\n",
    "non_matched_combined_labels = commonUtility.combine_labels(predicted_labels_names, actual_labels_names)\n",
    "imageVisualizationUtility.show(non_matched_results[\"images\"], non_matched_combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import gradcamUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Matched results\")\n",
    "# param image_weight: The final result is image_weight * img + (1-image_weight) * mask\n",
    "heatmap_overlaid_images = gradcamUtility.create_grad_cam_overlaid_images(new_loaded_model.model, \n",
    "                                                                         [new_loaded_model.model.layer3[-1]],\n",
    "                                                                         images=matched_results[\"images\"],\n",
    "                                                                         predictions_labels=matched_results[\"predicted_labels\"],\n",
    "                                                                         actual_labels=matched_results[\"actual_labels\"],\n",
    "                                                                         image_weight=0.98\n",
    "                                                                         )\n",
    "imageVisualizationUtility.show(heatmap_overlaid_images, matched_combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For Non-Matched results\")\n",
    "# param image_weight: The final result is image_weight * img + (1-image_weight) * mask\n",
    "heatmap_overlaid_images = gradcamUtility.create_grad_cam_overlaid_images(new_loaded_model.model, \n",
    "                                                                         [new_loaded_model.model.layer3[-1]],\n",
    "                                                                         images=non_matched_results[\"images\"],\n",
    "                                                                         predictions_labels=non_matched_results[\"predicted_labels\"],\n",
    "                                                                         actual_labels=non_matched_results[\"actual_labels\"],\n",
    "                                                                         image_weight = 0.98\n",
    "                                                                         )\n",
    "imageVisualizationUtility.show(heatmap_overlaid_images, non_matched_combined_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
